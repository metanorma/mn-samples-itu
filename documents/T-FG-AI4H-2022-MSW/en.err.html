<html><head><title>/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.err.html errors</title>
<meta charset="UTF-8"/>
<style> pre { white-space: pre-wrap; }
thead th { font-weight: bold; background-color: aqua; }
.severity0 { font-weight: bold; background-color: lightpink }
.severity1 { font-weight: bold; }
.severity2 { }
.severity3 { font-style: italic; color: grey; }
</style>
</head><body><h1>/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.err.html errors</h1>
<ul><li><p><b><a href="#Style">Style</a></b>: Severity 2: <b>40</b> errors</p></li>

<li><p><b><a href="#Metanorma_XML_Syntax">Metanorma XML Syntax</a></b>: Severity 2: <b>1</b> errors</p></li>
</ul>
<h2 id="Style">Style</h2>
<table border="1">
<thead><th width="5%">Line</th><th width="20%">ID</th>
<th width="30%">Message</th><th width="40%">Context</th><th width="5%">Severity</th></thead>
<tbody>
<tr class="severity2">
<td></td><th><code>--</code></th>
<td>ITU-T FG-AI4H DEL01 does not match ITU document identifier conventions</td><td><pre></pre></td><td>2</td></tr>
<tr class="severity2">
<td>000027</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_summary'>_summary</a></code></th>
<td>Requirement possibly in preface: While AI holds great promise for the practice of public health and medicine,​ ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed</td><td><pre>&lt;abstract id=&quot;_summary&quot;&gt; &lt;title&gt;Summary&lt;/title&gt; &lt;p id=&quot;_53ff864f-355b-c791-c2d4-5685cc9d9387&quot;&gt;Artificial Intelligence (AI) refers to the ability of algorithms encoded in technology to learn from data so that they can perform automated tasks without every step in the process having to be programmed explicitly by a human. While AI holds great promise for the practice of public health and medicine, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed. Many of the ethical concerns described in this document predate the advent of AI, although AI itself presents a number of novel concerns.&lt;/p&gt;

&lt;p id=&quot;_dc49f3af-d63e-3336-fcbc-a99c0bad1c3e&quot;&gt;This document endorses a set of six key ethical principles:&lt;/p&gt;

&lt;ul id=&quot;_516e5f74-5a88-e6e5-6cb2-b560934d0a64&quot;&gt; &lt;li&gt; &lt;p id=&quot;_2100a27e-e669-494a-9c02-441f8370df91&quot;&gt;Protect human autonomy&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000240</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_executive_summary'>_​executive_summary</a></code></th>
<td>Requirement possibly in preface: AI systems must be carefully designed to reflect the diversity of socio-economic and health-care settings and be accompanied by training in digital skills, community engagement and awareness-raising</td><td><pre>&lt;clause id=&quot;_executive_summary&quot; inline-header=&quot;false&quot; obligation=&quot;informative&quot;&gt;
&lt;title&gt;Executive summary&lt;/title&gt;
&lt;p id=&quot;_fa0193bc-30d7-f3c5-16ce-e19ed93f75a7&quot;&gt;Artificial Intelligence (AI) refers to the ability of algorithms encoded in technology to learn from data so that they can perform automated tasks without every step in the process having to be programmed explicitly by a human. WHO recognizes that AI holds great promise for the practice of public health and medicine. WHO also recognizes that, to fully reap the benefits of AI, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed. Many of the ethical concerns described in this document predate the advent of AI, although AI itself presents a number of novel concerns.&lt;/p&gt;

&lt;p id=&quot;_d361af5e-9574-5632-5291-22a57501358a&quot;&gt;Whether AI can advance the interests of patients and communities depends on a collective effort to design and implement ethically defensible laws and policies and ethically designed AI technologies. There are also potential serious negative consequences if ethical principles and human rights obligations are not prioritized by those who fund, design, regulate or use AI technologies for health. AI&apos;s opportunities and challenges are thus inextricably linked.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000240</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_executive_summary'>_​executive_summary</a></code></th>
<td>Requirement possibly in preface: Health-care workers and health systems must have access to education and training in order to use and maintain these systems under the conditions for their safe, effective use</td><td><pre>&lt;clause id=&quot;_executive_summary&quot; inline-header=&quot;false&quot; obligation=&quot;informative&quot;&gt;
&lt;title&gt;Executive summary&lt;/title&gt;
&lt;p id=&quot;_fa0193bc-30d7-f3c5-16ce-e19ed93f75a7&quot;&gt;Artificial Intelligence (AI) refers to the ability of algorithms encoded in technology to learn from data so that they can perform automated tasks without every step in the process having to be programmed explicitly by a human. WHO recognizes that AI holds great promise for the practice of public health and medicine. WHO also recognizes that, to fully reap the benefits of AI, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed. Many of the ethical concerns described in this document predate the advent of AI, although AI itself presents a number of novel concerns.&lt;/p&gt;

&lt;p id=&quot;_d361af5e-9574-5632-5291-22a57501358a&quot;&gt;Whether AI can advance the interests of patients and communities depends on a collective effort to design and implement ethically defensible laws and policies and ethically designed AI technologies. There are also potential serious negative consequences if ethical principles and human rights obligations are not prioritized by those who fund, design, regulate or use AI technologies for health. AI&apos;s opportunities and challenges are thus inextricably linked.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000240</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_executive_summary'>_​executive_summary</a></code></th>
<td>Requirement possibly in preface: To unlock this potential, health-care workers and health systems must have detailed information on the contexts in which such systems can function safely and effectively, the conditions necessary to ensure reliable,​ appropriate use, and the mechanisms for continuous auditing and assessment of system performance</td><td><pre>&lt;clause id=&quot;_executive_summary&quot; inline-header=&quot;false&quot; obligation=&quot;informative&quot;&gt;
&lt;title&gt;Executive summary&lt;/title&gt;
&lt;p id=&quot;_fa0193bc-30d7-f3c5-16ce-e19ed93f75a7&quot;&gt;Artificial Intelligence (AI) refers to the ability of algorithms encoded in technology to learn from data so that they can perform automated tasks without every step in the process having to be programmed explicitly by a human. WHO recognizes that AI holds great promise for the practice of public health and medicine. WHO also recognizes that, to fully reap the benefits of AI, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed. Many of the ethical concerns described in this document predate the advent of AI, although AI itself presents a number of novel concerns.&lt;/p&gt;

&lt;p id=&quot;_d361af5e-9574-5632-5291-22a57501358a&quot;&gt;Whether AI can advance the interests of patients and communities depends on a collective effort to design and implement ethically defensible laws and policies and ethically designed AI technologies. There are also potential serious negative consequences if ethical principles and human rights obligations are not prioritized by those who fund, design, regulate or use AI technologies for health. AI&apos;s opportunities and challenges are thus inextricably linked.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000240</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_executive_summary'>_​executive_summary</a></code></th>
<td>Requirement possibly in preface: WHO also recognizes that, to fully reap the benefits of AI, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed</td><td><pre>&lt;clause id=&quot;_executive_summary&quot; inline-header=&quot;false&quot; obligation=&quot;informative&quot;&gt;
&lt;title&gt;Executive summary&lt;/title&gt;
&lt;p id=&quot;_fa0193bc-30d7-f3c5-16ce-e19ed93f75a7&quot;&gt;Artificial Intelligence (AI) refers to the ability of algorithms encoded in technology to learn from data so that they can perform automated tasks without every step in the process having to be programmed explicitly by a human. WHO recognizes that AI holds great promise for the practice of public health and medicine. WHO also recognizes that, to fully reap the benefits of AI, ethical challenges for health care systems, practitioners and beneficiaries of medical and public health services must be addressed. Many of the ethical concerns described in this document predate the advent of AI, although AI itself presents a number of novel concerns.&lt;/p&gt;

&lt;p id=&quot;_d361af5e-9574-5632-5291-22a57501358a&quot;&gt;Whether AI can advance the interests of patients and communities depends on a collective effort to design and implement ethically defensible laws and policies and ethically designed AI technologies. There are also potential serious negative consequences if ethical principles and human rights obligations are not prioritized by those who fund, design, regulate or use AI technologies for health. AI&apos;s opportunities and challenges are thus inextricably linked.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000669</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-3'>sec-3</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-3&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Applications of artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_b8681847-4e4d-88d2-d326-da33e5184964&quot;&gt;This section identifies AI technologies developed and used in HIC, although examples of such technologies are emerging (and being pilot-tested or used) in LMIC. Digital health technologies are already used widely in LMIC, including for data collection, dissemination of health information by mobile phones and extended use of electronic medical records on open-software platforms and cloud computing  &lt;eref type=&quot;inline&quot; bibitemid=&quot;wahl&quot; citeas=&quot;[326]&quot;/&gt;. Schwabe and Wahl  &lt;eref type=&quot;inline&quot; bibitemid=&quot;schwalbe&quot; citeas=&quot;[337]&quot;/&gt; have identified four uses of AI for health in LMIC: diagnosis, morbidity or mortality risk assessment, disease outbreak and surveillance, and health policy and planning.&lt;/p&gt;

&lt;clause id=&quot;sec-3-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000680</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-3-1'>sec-3-1</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-3-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;In health care&lt;/title&gt;
&lt;p id=&quot;_816ce032-2da2-de2f-52f1-cce0df03914d&quot;&gt;The use of AI in medicine raises notions of AI replacing clinicians and human decision-making. The prevailing sentiment is, however, that AI is increasingly improving diagnosis and clinical care, based on earlier definitions of the role of computers in medicine  &lt;eref type=&quot;inline&quot; bibitemid=&quot;miller&quot; citeas=&quot;[11]&quot;/&gt; and regulations in which AI is defined as a support tool (to improve judgement).&lt;/p&gt;

&lt;clause id=&quot;sec-3-1-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000768</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-3-1-3'>sec-3-1-3</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-3-1-3&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Emerging trends in the use of AI in clinical care&lt;/title&gt;
&lt;p id=&quot;_b5c68501-80ac-8e41-b29e-b8307cb5f3d1&quot;&gt;Several important changes imposed by the use of AI in clinical care extend beyond the provider-patient relationship. Four trends described here are: the evolving role of the patient in clinical care; the shift from hospital to home-based care; use of AI to provide &quot;clinical&quot; care outside the formal health system; and use of AI for resource allocation and prioritization. Each of these trends has ethical implications, as discussed below.&lt;/p&gt;

&lt;clause id=&quot;_the_evolving_role_of_the_patient_in_clinical_care&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>000989</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-3-4'>sec-3-4</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-3-4&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;In public health and public health surveillance&lt;/title&gt;
&lt;p id=&quot;_ded51006-735b-2ae2-8c62-43981073d18f&quot;&gt;Several AI tools for population and public health can be used in public health programmes. For example, new developments in AI could, after rigorous evaluation, improve identification of disease outbreaks and support surveillance. Several concerns about the use of technology for public health surveillance, promotion and outbreak response must, however, be considered before use of AI for such purposes, including the tension between the public health benefits of surveillance and ethical and legal concern about individual (or community) privacy and autonomy  &lt;eref type=&quot;inline&quot; bibitemid=&quot;who-guide&quot; citeas=&quot;[276]&quot;/&gt;.&lt;/p&gt;

&lt;clause id=&quot;sec-3-4-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>001151</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-4'>sec-4</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-4&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Laws, policies and principles that apply to artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_c1b1d746-8ca9-7dac-96e2-e44288d08508&quot;&gt;Laws, policies and principles for regulating and managing the use of AI and specifically use of AI for health are fragmented and limited. Numerous principles and guidelines have been developed for application of &quot;ethical&quot; AI in the private and public sectors and in research institutions  &lt;eref type=&quot;inline&quot; bibitemid=&quot;jobin&quot; citeas=&quot;[296]&quot;/&gt;; however, there is no consensus on its definition, best practices or ethical requirements, and different legal regimes and governance models are associated with each set of principles. Other norms, rules and frameworks also apply to use of AI, including human rights obligations, bioethics laws and policies, data protection laws and regulatory standards. These are summarized below and discussed elsewhere in the document. &lt;xref target=&quot;sec-5&quot;/&gt; provides a set of guiding principles agreed by the WHO Expert Group by consensus, on which this analysis and findings are based.&lt;/p&gt;

&lt;clause id=&quot;sec-4-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>001299</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_0ceb4f8d-10eb-073a-512f-5f18501e03b9'>_0ceb4f8d-10eb-073a-512f-5f18501e03b9</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_0ceb4f8d-10eb-073a-512f-5f18501e03b9&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_497098be-daba-4c04-d388-625c0212eb0e&quot;&gt; &lt;strong&gt;Box 1 — Examples of AI ethics principles proposed by intergovernmental organizations and countries&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_2b427882-b21a-4c3a-e838-b33efad3d168&quot;&gt;The Recommendations of the OECD Council on Artificial Intelligence &lt;eref type=&quot;inline&quot; bibitemid=&quot;oecd-legal&quot; citeas=&quot;[316]&quot;/&gt;, the first intergovernmental standard on AI, were adopted in May 2019 by OECD&apos;s 36 member countries and have since been applied by a number of partner economies. The OECD AI principles  &lt;eref type=&quot;inline&quot; bibitemid=&quot;going-digital&quot; citeas=&quot;[317]&quot;/&gt; provided the basis for the AI principles endorsed by G20 governments in June 2019  &lt;eref type=&quot;inline&quot; bibitemid=&quot;eee-digital&quot; citeas=&quot;[318]&quot;/&gt;. While OECD recommendations are not legally binding, they carry a political commitment and have proved highly influential in setting international standards in other policy areas (e.g., privacy and data protection) and helping governments to design national legislation. The OECD launched an online platform for public policy on AI, the AI Policy Observatory &lt;eref type=&quot;inline&quot; bibitemid=&quot;oecd-ai&quot; citeas=&quot;[319]&quot;/&gt; (See &lt;xref target=&quot;sec-9-6&quot;/&gt;.) and is cooperating on this and other initiatives on the ethical implications of AI with the Council of Europe, the United Nations Economic, Scientific and Cultural Organization (UNESCO) and WHO.&lt;/p&gt;

&lt;ul id=&quot;_0f551a6e-1eae-3000-336d-378477d4bebc&quot;&gt; &lt;li&gt; &lt;p id=&quot;_5b9ece64-f394-b74e-4ed2-3f01ca882d1b&quot;&gt;In 2019, the Council of Europe Commissioner for Human Rights issued recommendations to ensure that human rights are strengthened rather than undermined by AI: Unboxing artificial intelligence: 10 steps to protect human rights recommendations  &lt;eref type=&quot;inline&quot; bibitemid=&quot;unboxing-ai10&quot; citeas=&quot;[320]&quot;/&gt;.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>001417</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-5'>sec-5</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-5&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Key ethical principles for use of artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_bc18c1ff-235e-f46c-c84e-f957204950bf&quot;&gt;Ethical principles for the application of AI for health and other domains are intended to guide developers, users and regulators in improving and overseeing the design and use of such technologies. Human dignity and the inherent worth of humans are the central values upon which all other ethical principles rest.&lt;/p&gt;

&lt;p id=&quot;_8cf1d87d-5d83-8b3a-9e05-faca9546e493&quot;&gt;An ethical principle is a statement of a duty or a responsibility in the context of the development, deployment and continuing assessment of AI technologies for health. The ethical principles described below are grounded in basic ethical requirements that apply to all persons and that are considered noncontroversial. The requirements are as follows.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>001777</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6'>sec-6</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Ethical challenges to use of artificial intelligence for health care&lt;/title&gt;
&lt;p id=&quot;_4d55f0d8-5b80-4a4b-90e0-120408ccd4c0&quot;&gt;Several ethical challenges are emerging with the use of AI for health, many of which are especially relevant to LMIC. These challenges must be addressed if AI technologies are to support achievement of universal health coverage. Use of AI to extend health-care coverage and services in marginalized communities in HIC can raise similar ethical concerns, including an enduring digital divide, lack of good-quality data, collection of data that incorporate clinical biases (as well as inappropriate data collection practices) and lack of treatment options after diagnosis.&lt;/p&gt;

&lt;clause id=&quot;sec-6-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>001971</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6-3'>sec-6-3</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6-3&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Data collection and use&lt;/title&gt;
&lt;p id=&quot;_abc30c3f-d329-e84a-ec1b-3068ec5f0cde&quot;&gt;The collection, analysis and use of health data, including from clinical trials, laboratory results and medical records, is the bedrock of medical research and the practice of medicine. Over the past two decades, the data that qualify as health data have expanded dramatically. They now include massive quantities of personal data about individuals from many sources, including genomic data, radiological images, medical records and non-health data converted into health data  &lt;eref type=&quot;inline&quot; bibitemid=&quot;vayena&quot; citeas=&quot;[15]&quot;/&gt;. The various types of data, collectively known as &quot;biomedical big data&quot;, form a health data ecosystem that includes data from standard sources (e.g., health services, public health, research) and further sources (environmental, lifestyle, socioeconomic, behavioural and social). See  &lt;xref target=&quot;fig1&quot;/&gt; &lt;eref type=&quot;inline&quot; bibitemid=&quot;evolving-health-ecosystem&quot; citeas=&quot;[16]&quot;/&gt;.&lt;/p&gt;

&lt;figure id=&quot;fig1&quot; width=&quot;803&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002032</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_a10ca87f-809c-008d-3943-111bf8cdf296'>_a10ca87f-809c-008d-3943-111bf8cdf296</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_a10ca87f-809c-008d-3943-111bf8cdf296&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_4c75e53b-22a4-e30a-323c-a06b635e1b34&quot;&gt; &lt;strong&gt;Box 2 — The emergence of digital identification in the COVID-19 pandemic&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_24660710-1e1a-338b-3e38-71d846e8c3c9&quot;&gt;The COVID-19 pandemic is expanding and accelerating the creation of infrastructure for digital identities to store health data for several uses. In China, a QR code system has been established from the digital payment system established by Alipay, a mobile and online payment platform, to introduce an &quot;Alipay Health Code&quot;, in which the data collected are used to establish an algorithm to &quot;draw automated conclusions as to whether someone is a contagion risk&quot;  &lt;eref type=&quot;inline&quot; bibitemid=&quot;mozur&quot; citeas=&quot;[21]&quot;/&gt;. For a national programme to vaccinate millions of people against SARS-Cov2, India may use its national digital ID system, Aadhar, to avoid duplication and to track beneficiaries  &lt;eref type=&quot;inline&quot; bibitemid=&quot;angwadi&quot; citeas=&quot;[23]&quot;/&gt;. Many entities around the world, including travel firms, airports, some governments and political leaders, as well as the digital ID industry, are calling for the introduction of immunity passports or a digital &quot;credential given to a person who is assumed to be immune from SARS-CoV2 and so protected against re-infection&quot; &lt;eref type=&quot;inline&quot; bibitemid=&quot;immunity-pass&quot; citeas=&quot;[24]&quot;/&gt;. In some countries, technologies such as proximity-tracking applications have been credited with improving the response to the pandemic, because there was already a system in place to support the use of such technologies, effective communication, widespread adoption and a &quot;social compact&quot; between policy-makers and the public  &lt;eref type=&quot;inline&quot; bibitemid=&quot;fisherm&quot; citeas=&quot;[25]&quot;/&gt;.&lt;/p&gt;

&lt;p id=&quot;_7fe4e93e-91b2-96ed-2bb9-91500e09019f&quot;&gt;For many of these technologies, however, there is concern about whether they are effective (scientifically valid), whether they will create forms of discrimination or targeting of certain populations and whether they may exclude certain segments of the population or not be applicable by people who do not have access to the appropriate technology and infrastructure. They also raise concern about the generation of a permanent digital identity for individuals linked to their health and personal data, for which they may not have given consent, which could permanently undermine individual autonomy and privacy  &lt;eref type=&quot;inline&quot; bibitemid=&quot;looming-disaster&quot; citeas=&quot;[26]&quot;/&gt;. In particular, there is concern that governments could use such information to establish mass surveillance or scoring systems to monitor everyday activities, or companies could use such data and systems for other purposes  &lt;eref type=&quot;inline&quot; bibitemid=&quot;fair-shot&quot; citeas=&quot;[27]&quot;/&gt;.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002090</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_ed4142a5-7eea-4608-87b7-f2143e8f80cd'>_ed4142a5-7eea-4608-87b7-f2143e8f80cd</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_ed4142a5-7eea-4608-87b7-f2143e8f80cd&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_9b7d87a3-3aff-0218-740a-ea8a40d97df9&quot;&gt; &lt;strong&gt;Box 3 — Dinerstein vs Google&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_06c36769-2c36-4dfd-8fb2-32e8fc170bd4&quot;&gt;Google announced a strategic partnership with the University of Chicago and the University of Chicago Medicine in the USA in May 2017  &lt;eref type=&quot;inline&quot; bibitemid=&quot;wood&quot; citeas=&quot;[34]&quot;/&gt;. The aim of the partnership was to develop novel machine-learning tools to predict medical events such as unexpected hospital admissions. To realize this goal, the University shared hundreds of thousands of &quot;de-identified&quot; patients&apos; records with Google. One of the University&apos;s patients, Matt Dinerstein, filed a class action complaint against the University and Google in June 2019 on behalf of all patients whose records were disclosed  &lt;eref type=&quot;inline&quot; bibitemid=&quot;shachar&quot; citeas=&quot;[35]&quot;/&gt;.&lt;/p&gt;

&lt;p id=&quot;_c8d47b72-04c6-463d-5999-4f716404ad42&quot;&gt;Dinerstein brought several claims, including breach of contract, against the University and Google, alleging prima facie violation of the US Health Insurance Portability and Accountability Act. According to an article published in 2018 by the defendants  &lt;eref type=&quot;inline&quot; bibitemid=&quot;rajkomar&quot; citeas=&quot;[36]&quot;/&gt;, the patients&apos; medical records shared with Google &quot;were de-identified, except that dates of service were maintained in the (…​) dataset&quot;. The dataset also included &quot;free-text medical notes&quot;  &lt;eref type=&quot;inline&quot; bibitemid=&quot;rajkomar&quot; citeas=&quot;[36]&quot;/&gt;. Dinerstein accused the defendants of insufficient anonymization of the records, putting the patients&apos; privacy at risk. He alleged that the patients could easily be re-identified by Google by combining the records with other available data sets, such as geolocation data from Google Maps (by so-called &quot;data triangulation&quot;). Moreover, Dinerstein asserted that the University had not obtained express consent from each patient to share their medical records with Google, despite the technology giant&apos;s commercial interest in the data.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002261</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6-4'>sec-6-4</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6-4&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Accountability and responsibility for decision-making with artificial intelligence&lt;/title&gt;
&lt;p id=&quot;_f283d965-2705-1b88-082f-4d0efaf1af16&quot;&gt;This section addresses the challenges of assigning responsibility and accountability for the use of AI for health care, a guiding principle noted in  &lt;xref target=&quot;sec-5&quot;/&gt;. Much of the momentum of AI is based on the notion that use of such technologies for diagnosis, care or systems could improve clinical and institutional decision-making for health care. Clinicians and health-care workers have numerous cognitive biases and commit diagnostic errors. The US National Academy of Sciences found that 5% of US adults who seek health advice receive erroneous diagnoses and that such errors account for 10% of all patient deaths  &lt;eref type=&quot;inline&quot; bibitemid=&quot;grote&quot; citeas=&quot;[54]&quot;/&gt;. At the institutional level, machine learning might reduce inefficiency and errors and ensure more appropriate allocation of resources, if the underlying data are both accurate and representative  &lt;eref type=&quot;inline&quot; bibitemid=&quot;grote&quot; citeas=&quot;[54]&quot;/&gt;.&lt;/p&gt;

&lt;p id=&quot;_07547c8d-f333-7d25-2af6-791cfe23ac4b&quot;&gt;AI-guided decision-making also introduces several trade-offs and risks. One set of trade-offs is associated with the displacement of human judgement and control and concern about using AI to predict a person&apos;s health status or the evolution of disease. This is a major ethical and epistemological challenge to humans as the centre of production of knowledge and also to the system of production of knowledge for medicine. These considerations are addressed in  &lt;xref target=&quot;sec-6-5&quot;/&gt;.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002416</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6-5'>sec-6-5</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6-5&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Autonomous decision-making&lt;/title&gt;
&lt;p id=&quot;_2569dc35-18e0-03b2-04b9-012d8eef1261&quot;&gt;Decision-making has not yet been &quot;fully transferred&quot; from humans to machines in health care. While AI is used only to augment human decision-making in the practice of public health and medicine, epistemic authority has, in some circumstances, been displaced, whereby AI systems (such as with the use of computer simulations) are displacing humans from the centre of knowledge production ( &lt;eref type=&quot;inline&quot; bibitemid=&quot;duran&quot; citeas=&quot;[68]&quot;/&gt;, &lt;eref type=&quot;inline&quot; bibitemid=&quot;humphreys&quot; citeas=&quot;[69]&quot;/&gt;). Furthermore, there are signs of full delegation of routine medical functions to AI. Delegation of clinical judgement introduces concern about whether full delegation is legal, as laws increasingly recognize the right of individuals not to be subject to solely automated decisions when such decisions would have a significant effect. Full delegation also creates a risk of automation bias on the part of the provider, as discussed above. Other concerns could emerge if human judgement is increasingly replaced by machine-guided judgement, and wider ethical concern would arise with loss of human control, especially if prediction-based health care becomes the norm. Yet, as for autonomous cars, it is unlikely that AI in medicine will ever achieve full autonomy. It may achieve only conditional automation or require human back-up  &lt;eref type=&quot;inline&quot; bibitemid=&quot;topol&quot; citeas=&quot;[70]&quot;/&gt;.&lt;/p&gt;

&lt;clause id=&quot;sec-6-5-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002526</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_c9ec7d5e-2c06-1ea5-ccf2-65b5dc2ca45f'>_c9ec7d5e-2c06-1ea5-ccf2-65b5dc2ca45f</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_c9ec7d5e-2c06-1ea5-ccf2-65b5dc2ca45f&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_c8f7d9a8-e045-7336-978d-08c708c6a9cc&quot;&gt; &lt;strong&gt;Box 4 — Informed consent during clinical care&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_3671e4c0-7ff9-0085-b87f-62d04056cf09&quot;&gt;Consider use of an AI in a hospital to make recommendations on a drug and dosage for a patient. The AI recommends a particular drug and dosage for patient A. The physician does not, however, understand how the AI reached its recommendation. The AI has a highly sophisticated algorithm and is thus a black box for the physician. Should the physician follow the AI&apos;s recommendation? If patients were to find out that an AI or machine-learning system was used to recommend their care but no one had told them, how would they feel? Does the physician have a moral or even a legal duty to tell patient A that he or she has consulted an AI technology? If so, what essential information should the physician provide to patient A? Should disclosure of the use of AI be part of obtaining informed consent and should a lack of sufficient information incur liability? &lt;eref type=&quot;inline&quot; bibitemid=&quot;cohen&quot; citeas=&quot;[74]&quot;/&gt; &lt;/p&gt;

&lt;p id=&quot;_bd6c4d33-9397-2f89-0a2f-5a52b936ba92&quot;&gt;Transparency is crucial to promoting trust among all stakeholders, particularly patients. Physicians should be frank with patients from the onset and inform them of the use of AI rather than hiding the technology. They should try their best to explain to their patients the purpose of using AI, how it functions and whether it is explainable. They should describe what data are collected, how they are used and shared with third parties and the safeguards for protection of patients&apos; privacy. Physicians should also be transparent about any weaknesses of the AI technology, such as any biases, data breaches or privacy concerns. Only with transparency can the deployment of AI for health care and health science, including hospital practice and clinical trials  &lt;eref type=&quot;inline&quot; bibitemid=&quot;minssen&quot; citeas=&quot;[75]&quot;/&gt;, become a long-term success. Trust is key to facilitating the adoption of AI in medicine.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002729</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_00029609-814d-482a-4377-3ad17b67c69a'>_00029609-814d-482a-4377-3ad17b67c69a</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_00029609-814d-482a-4377-3ad17b67c69a&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_34c0e936-82a2-8767-cee5-58b2754703c1&quot;&gt; &lt;strong&gt;Box 5 — Challenges associated with a system for predicting adolescent pregnancy in Argentina&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_30606cc2-cc98-580f-2303-0bb939e0e0cc&quot;&gt;In 2017, the province of Salta, Argentina, signed an agreement with Microsoft to use AI to prevent adolescent pregnancy, a public health objective, and a tool to prevent school dropout. Microsoft used data for AI training collected by the local government from populations in vulnerable situations. The local authorities described the system  &lt;eref type=&quot;inline&quot; bibitemid=&quot;urtubey&quot; citeas=&quot;[95]&quot;/&gt; as:&lt;/p&gt;

&lt;quote id=&quot;_4c8073b3-db75-ca77-52e9-b151a5fbaecd&quot;&gt; &lt;p id=&quot;_5fd888c2-0022-3458-55bb-1100e131b178&quot;&gt;intelligent algorithms that identify characteristics in people that can lead to some of these problems [adolescent pregnancy and school dropout] and warn the government so that they can work on prevention.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002808</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6-6'>sec-6-6</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6-6&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Bias and discrimination associated with artificial intelligence&lt;/title&gt;
&lt;p id=&quot;_54b916dd-755c-d0fa-7d39-cbceac8b5355&quot;&gt;Societal bias and discrimination are often replicated by AI technologies, including those used in the criminal justice system, banking, human resources and the provision of public services. The different forms of discrimination and bias that a person or a group of people suffer because of identities such as gender, race and sexual orientation must be considered. Racial bias (in the USA and other countries) is affecting the performance of AI technologies for health (Box 6).&lt;/p&gt;

&lt;table id=&quot;_c6cbea1b-f9c1-1d58-0b5b-e122d9d876a3&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_f2b436fc-5032-a69d-7c4c-4c5b6eabbf31&quot;&gt; &lt;strong&gt;Box 6 — Discrimination and racial bias in AI technology&lt;/strong&gt; &lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002817</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_c6cbea1b-f9c1-1d58-0b5b-e122d9d876a3'>_c6cbea1b-f9c1-1d58-0b5b-e122d9d876a3</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_c6cbea1b-f9c1-1d58-0b5b-e122d9d876a3&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_f2b436fc-5032-a69d-7c4c-4c5b6eabbf31&quot;&gt; &lt;strong&gt;Box 6 — Discrimination and racial bias in AI technology&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_cd5e1a48-1876-e105-c02d-0f9a46eac297&quot;&gt;In a study published in Science in October 2019 &lt;eref type=&quot;inline&quot; bibitemid=&quot;obermeyer&quot; citeas=&quot;[101]&quot;/&gt;, researchers found significant racial bias in an algorithm used widely in the US health-care system to guide health decisions. The algorithm is based on cost (rather than illness) as a proxy for needs; however, the US health-care system spent less money on Black than on white patients with the same level of need. Thus, the algorithm incorrectly assumed that white patients were sicker than equally sick Black patients. The researchers estimated that the racial bias reduced the number of Black patients receiving extra care by more than half.&lt;/p&gt;

&lt;p id=&quot;_d0cf4411-5bc2-3720-2d20-513e041516f0&quot;&gt;This case highlights the importance of awareness of biases in AI and mitigating them from the onset to prevent discrimination (based on, e.g., race, gender, age or disability). Biases may be present not only in the algorithm but also, for example, in the data used to train the algorithm. Many other types of bias, such as contextual bias ( &lt;eref type=&quot;inline&quot; bibitemid=&quot;prince-wn&quot; citeas=&quot;[102]&quot;/&gt;, &lt;eref type=&quot;inline&quot; bibitemid=&quot;minssen-regulatory&quot; citeas=&quot;[103]&quot;/&gt;), should be considered. Stakeholders, particularly AI programmers, should apply &quot;ethics by design&quot; and mitigate biases at the outset in developing a new AI technology for health  &lt;eref type=&quot;inline&quot; bibitemid=&quot;gerkes&quot; citeas=&quot;[104]&quot;/&gt;.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002868</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_1636f651-5839-79ee-023c-d8147adeb7db'>_1636f651-5839-79ee-023c-d8147adeb7db</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_1636f651-5839-79ee-023c-d8147adeb7db&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_5463fa80-970f-069f-31f0-bbcd1a3443a9&quot;&gt; &lt;strong&gt;Box 7 — AI technologies for detecting skin cancer exclude people of colour&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_e8ce7f39-a7c6-3d81-466b-8cd0cf5f2cd3&quot;&gt;Machine learning has outperformed dermatologists in detecting potentially cancerous skin lesions. As rates of skin cancer increase in many countries, AI technology would improve the ability of dermatologists to diagnose skin cancer. The data used to train one highly accurate machine-learning model are, however, for &quot;fair-skinned&quot; populations in Australia, Europe and the USA. Thus, while the technology assists in diagnosis, prevention and treatment of skin cancer in white and light-skinned individuals, the algorithm was neither appropriate nor relevant for people of colour, as it was not trained on images of these populations.&lt;/p&gt;

&lt;p id=&quot;_8afeb24f-a56a-fdfa-5bfc-67ee9e7b5560&quot;&gt;The inadequacy of the data on people of colour is due to several structural factors, including lack of medical professionals and of adequate information in communities of colour and economic barriers that prevent marginalized communities from seeking health care or participating in research that would allow such individuals to contribute data.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>002964</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-6-7'>sec-6-7</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-6-7&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Risks of artificial intelligence technologies to safety and cybersecurity&lt;/title&gt;
&lt;p id=&quot;_8a496d29-087a-217b-1aae-8832b9773cf0&quot;&gt;This section discusses several risks for safety and cybersecurity associated with use of AI technologies for health, which may be generalized to the use of many computing technologies for health care — past and present.&lt;/p&gt;

&lt;clause id=&quot;sec-6-7-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>003312</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-7'>sec-7</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-7&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Building an ethical approach to use of artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_8621a834-69d6-95c7-5233-4e6bf9a11407&quot;&gt;This section addresses how measures other than law and policy can ensure that AI improves human health and well-being.&lt;/p&gt;

&lt;clause id=&quot;sec-7-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>003317</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-7-1'>sec-7-1</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-7-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Ethical, transparent design of technologies&lt;/title&gt;
&lt;p id=&quot;_d8022e1e-e123-bd18-0e80-7d149af39e82&quot;&gt;Although technology designers and developers play critical roles in designing AI tools for use in health, there are no procedures for credentialing or licensing such as those required for health-care workers. In the absence of formal qualifications for ethics in the AI field, it is not enough merely to call for personal adherence to values such as reproducibility, transparency, fairness and human dignity.&lt;/p&gt;

&lt;p id=&quot;_616be930-3c97-d630-9c0c-74b0243e63cf&quot;&gt;New approaches to software engineering in the past decade move beyond an appeal to abstract moral values, and improvements in design methods are not merely upgraded programming techniques. Methods for designing AI technologies that include moral values in health and other sectors have been proposed to support effective, systematic, transparent integration of ethical values. Such values in design have also been codified legally; for example, the GDPR includes specific obligations to include privacy by design and by default.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>003340</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_f870dba1-412b-d338-5ddb-56af15ddced2'>_f870dba1-412b-d338-5ddb-56af15ddced2</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_f870dba1-412b-d338-5ddb-56af15ddced2&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_664ed9c1-64cb-194a-29aa-f706fb3ede32&quot;&gt; &lt;strong&gt;Box 8 — Design for values &lt;eref type=&quot;inline&quot; bibitemid=&quot;aizenberg&quot; citeas=&quot;[143]&quot;/&gt; &lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_ec07a7f9-26b3-3177-d7b5-354a910cb873&quot;&gt;&quot;Design for values&quot; is explicit transposition of moral and social values into context-dependent design requirements. It is an umbrella term for several pioneering methods, such as value-sensitive design, values in design and participatory design. Design for values presents a roadmap for stakeholders to translate human rights into context-dependent design requirements through a structured, inclusive, transparent process, such that abstract values are translated into design requirements and norms (properties that a technology should have to ensure certain values), and the norms then become a socio-technical design requirement. The process of identifying design requirements permits all stakeholders, including individuals affected by the technology, users, engineers, field experts and legal practitioners, to debate design choices and identify the advantages and shortcomings of each choice.&lt;/p&gt;

&lt;p id=&quot;_879bba6f-9de6-9859-9273-bd6f1f670ff8&quot;&gt;Thus, a value such as privacy can be interpreted through certain norms, such as informed consent, right to erasure and confidentiality. These norms can then be converted by discussion and consultation into design requirements, such as positive opt-in (a means of ensuring informed consent) or homomorphic encryption techniques to assure confidentiality. Other techniques for safeguarding privacy, such as &lt;em&gt;k&lt;/em&gt;-anonymity, differential privacy and coarse graining through clustering, could also be selected through consultation.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>003574</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#_b7932b7d-103a-d9d9-2a2a-295881f16643'>_b7932b7d-103a-d9d9-2a2a-295881f16643</a></code></th>
<td>Table should have title</td><td><pre>&lt;table id=&quot;_b7932b7d-103a-d9d9-2a2a-295881f16643&quot; unnumbered=&quot;true&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td valign=&quot;top&quot; align=&quot;left&quot;&gt; &lt;p id=&quot;_3c19c4ed-13e1-8f3b-b64a-db350d4ca824&quot;&gt; &lt;strong&gt;Box 9 — Supporting health workers in the use AI technologies, including through education and training&lt;/strong&gt; &lt;/p&gt;

&lt;p id=&quot;_0b0154c7-8cfc-6c26-21ab-da0414efdfb9&quot;&gt;Medical professionals and health-care workers should receive sufficient technical, managerial and administrative support, capacity-building, regulatory protection (when appropriate) and training in the many uses of AI technologies and their advantages and in navigating the ethical challenges of AI  &lt;eref type=&quot;inline&quot; bibitemid=&quot;paranjape&quot; citeas=&quot;[160]&quot;/&gt;. With regard to education and training, AI curricula should be seamlessly integrated into existing programmes  &lt;eref type=&quot;inline&quot; bibitemid=&quot;paranjape&quot; citeas=&quot;[160]&quot;/&gt;. Curricula should be updated regularly, as AI is evolving continuously. Some members of the health-care profession will require training in basic use of computers before they adapt to use of AI. All health-care professionals will require a certain level of digital literacy, defined in the Topol review as &quot;those digital capabilities that fit someone for living, learning, working, participating and thriving in a digital society&quot;  &lt;eref type=&quot;inline&quot; bibitemid=&quot;topol-preparing&quot; citeas=&quot;[166]&quot;/&gt;.&lt;/p&gt;

&lt;p id=&quot;_5939ee4f-86c2-8364-b479-ed7c1726195c&quot;&gt;Physicians and nurses will also require a wider range of competence to apply AI in clinical practice, including better understanding of mathematical concepts, the fundamentals of AI, data science, health data provenance, curation, integration and governance  &lt;eref type=&quot;inline&quot; bibitemid=&quot;topol-preparing&quot; citeas=&quot;[166]&quot;/&gt;, and also of the ethical and legal issues associated with the use of AI for health. Such measures (including training) will be necessary to combine and analyse data from many sources adequately, supervise AI tools and detect inaccurate performance of AI  &lt;eref type=&quot;inline&quot; bibitemid=&quot;paranjape&quot; citeas=&quot;[160]&quot;/&gt;. Good support and training will ensure that health-care workers and physicians, for example, can avoid common pitfalls such as automation bias when using AI technologies. Eventually, the knowledge, skills and capabilities required of health workers may be defined by professional and statutory regulatory bodies in collaboration with practitioners and educators  &lt;eref type=&quot;inline&quot; bibitemid=&quot;topol-preparing&quot; citeas=&quot;[166]&quot;/&gt;.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>003777</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-8'>sec-8</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-8&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Liability regimes for artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_7258ea5c-66fb-5437-defc-1852fe71cbc8&quot;&gt;Although the performance of machine-learning algorithms is improving, there will still be errors and mistakes, for example because an algorithm has been trained with incomplete or inappropriate data, programming mistakes or security flaws. Even AI technologies designed with well-curated data and an appropriate algorithm could harm an individual. While AI technologies may be safe in practice, unforeseeable risks are likely  &lt;eref type=&quot;inline&quot; bibitemid=&quot;rahwan&quot; citeas=&quot;[170]&quot;/&gt;.&lt;/p&gt;

&lt;p id=&quot;_09c3212e-a5c8-c8fb-498e-ca6311135cc6&quot;&gt;Lawmakers and regulators should ensure that rules and frameworks for safety are applicable to the use of AI technologies for health care and that they are proactively integrated into the design and deployment of AI-guided technologies. Updated liability rules for the use of AI in clinical care and medicine should at least include the same standards and damages already applied to health care. It is possible that reliance on AI technologies and the risks they may pose require additional obligations and damages. This section addresses how liability regimes could evolve, approaches to compensation, specific considerations for LMIC and the role of international institutions and organizations. It does not address liability that may arise from data processing.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>004002</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9'>sec-9</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Elements of a framework for governance of artificial intelligence for health&lt;/title&gt;
&lt;p id=&quot;_4bac6ca5-2f37-939d-bbbb-cf53af19def0&quot;&gt;Human rights standards, data protection laws and ethical principles are all necessary to guide, regulate and manage the use of AI for health by developers, governments, providers and patients. Many stakeholders have called for a commonly accepted set of ethical principles for AI for health, and WHO hopes that the principles suggested in this document (See  &lt;xref target=&quot;sec-5&quot;/&gt;.) will encourage consensus.&lt;/p&gt;

&lt;p id=&quot;_5f1b450f-905c-6a1f-7e05-241b543b6d69&quot;&gt;Use of AI for health introduces several challenges that cannot be resolved by ethical principles and existing laws and policies, in particular because the risks and opportunities of the use of AI are not yet well understood or will change over time. Furthermore, many principles, laws and standards were devised by and for HIC. LMIC will face additional challenges to introducing new AI technologies, which will require not only awareness of and adherence to ethical principles but also appropriate governance.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>004031</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9-1'>sec-9-1</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Governance of data&lt;/title&gt;
&lt;p id=&quot;_b49b4481-d212-01a5-f216-f57cc7e0eb8a&quot;&gt;The definition of &quot;health data&quot; has widened dramatically over the past two decades. Successful development of an AI system for use in health care relies on high-quality data, which are used to both train and validate the algorithmic model. This section addresses the evolution of individual consent with the proliferation of health data as well as the principles, legal frameworks and measures used by governments. This section also addresses principles and mechanisms designed and used to govern health data by communities, academic or health-care institutions, companies or governments, including how these entities should share health data.&lt;/p&gt;

&lt;clause id=&quot;sec-9-1-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>004455</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9-2'>sec-9-2</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9-2&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Control and benefit-sharing&lt;/title&gt;
&lt;p id=&quot;_15d94afe-1265-ae8b-11fd-37cca7c08272&quot;&gt;The application of big data and AI for health care raises questions about how to assess and govern data control, IP and other proprietary and privacy rights that might affect the use and control of medical data and AI-driven technologies. These include asserting exclusive rights over health datasets, algorithms, software and products that include AI and the outcomes of AI-based technologies, such as medicines and diagnostic technologies. Several wider questions should be resolved, including whether health big data can or should be controlled exclusively by individuals by an appropriate form of governance or by entities that may aggregate the data. (Control of personal data is discussed above.)&lt;/p&gt;

&lt;p id=&quot;_d44f8586-7694-52f4-abe7-db2066f81e4d&quot;&gt;A separate question is whether novel products created solely by a machine can be &quot;owned&quot; and, if so, whether ownership rights are conferred on the machine or on the entity that created or controls the machine. There is also the question of assigning appropriate value to the public&apos;s contribution to development of new AI technologies, such as investment in the development of algorithms, provision of data by individuals and health systems and from health data hubs accessed by private actors for the development of new AI technologies. If AI technologies are increasingly protected by exclusive rights, there is the wider question of whether they will be available, appropriate and affordable in LMIC.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>004662</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9-3'>sec-9-3</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9-3&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Governance of the private sector&lt;/title&gt;
&lt;p id=&quot;_eb99c374-25c1-0362-0e90-fe770a1c561e&quot;&gt;The private sector plays a central role in the development and delivery of AI for health care. The &quot;private sector&quot; ranges from small start-ups to the world&apos;s largest technology companies, as well as companies that provide many of the materials necessary for AI, including health data collected by companies that supply wearable devices, data aggregators and software firms that write new algorithms for use in health care. Furthermore, many companies that were already providing products and services are transforming their businesses to integrate AI and big data. These include biopharmaceutical companies, diagnostic and medical device firms, insurance companies, private hospitals and health-care providers. Companies that are developing AI technologies for use in health care are also providing these applications and services outside the health-care system, raising the question of how such health-care provision should be regulated.&lt;/p&gt;

&lt;p id=&quot;_cf282d1c-57c8-9210-4397-b40d110e354b&quot;&gt;This section addresses several issues related to the governance of such companies: To what extent should oversight and governance of the private sector be enforced by companies collectively or individually? What challenges and opportunities for effective governance are associated with PPPs for AI for health care? What are the challenges of oversight and governance of large technology companies involved in the use of AI for health? How should governments manage the growth of health-care services provided by companies outside the health system? How can governments ensure that they are effectively overseeing the private sector?&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>004989</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9-4'>sec-9-4</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9-4&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Governance of the public sector&lt;/title&gt;
&lt;p id=&quot;_b1bad49f-96a7-de51-45fb-25f1b001ce78&quot;&gt;Use of AI in the public sector has increased recently, although it lags behind adoption by the private sector. In 2019, OECD identified 50 countries that have launched or are planning to launch national AI strategies, of which 36 plan to or have issued separate strategies for public sector AI  &lt;eref type=&quot;inline&quot; bibitemid=&quot;hello-world&quot; citeas=&quot;[245]&quot;/&gt;. In 2017, the United Arab Emirates was the first country in the world to have a designated minister for AI, which has resulted in increased use of AI in the health-care system, such as &quot;pods&quot; to detect early signs of illness, AI-enabled telemedicine and use of AI to detect diabetic retinopathy  &lt;eref type=&quot;inline&quot; bibitemid=&quot;ai-uae&quot; citeas=&quot;[246]&quot;/&gt;. Although use of AI has increased in the public sector, a review of nearly 1700 studies found only 59 on use of AI in the public sector  &lt;eref type=&quot;inline&quot; bibitemid=&quot;hello-world&quot; citeas=&quot;[245]&quot;/&gt;. There is no comprehensive account of how governments are advancing the use of AI or integrating it into health care. The OECD identified six broad roles for governments in AI, as a:&lt;/p&gt;

&lt;ul id=&quot;_9d6d8358-04a0-5e13-3f38-ac5d45829e13&quot;&gt; &lt;li&gt; &lt;p id=&quot;_26359fd5-762a-2ddd-c489-aab08a0fa8b2&quot;&gt;financier or direct investor in AI technologies in both the public and the private sector;&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>005161</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-9-5'>sec-9-5</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-9-5&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Regulatory considerations&lt;/title&gt;
&lt;p id=&quot;_952c601f-9b3e-431b-f4ff-b8fd680e8ec0&quot;&gt;The largest national regulatory agencies, such as the Food and Drug Administration in the USA, have been developing guidance and protocols to ensure the safety and efficacy of new AI technologies; however, other regulatory agencies may have neither the capacity nor the expertise to approve use of such devices. A WHO working group has been formed to address regulatory considerations for the use of AI for health care and drug development and will issue a report and recommendations in 2021. The present guidance identifies several ethical concerns that could be addressed by regulatory agencies and the challenges that could arise.&lt;/p&gt;

&lt;clause id=&quot;sec-9-5-1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>006620</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#annexA'>annexA</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;annex id=&quot;annexA&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Considerations for the ethical design, deployment and use of artificial intelligence technologies for health&lt;/title&gt;
&lt;p id=&quot;_8cb979d8-744c-d297-342e-5a1344302352&quot;&gt;The following provides practical guidance for several key groups that use AI in the health field: AI designers and developers, ministries of health and health care institutions and providers. It reflects the main principles, ideas and recommendations in this document.&lt;/p&gt;

&lt;clause id=&quot;sec-a1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>006627</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-a1'>sec-a1</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-a1&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Considerations for AI developers&lt;/title&gt;
&lt;p id=&quot;_5a3595d3-8607-598f-5f4c-9bf67b9ac6b9&quot;&gt;The following considerations are for individuals, research organizations and companies involved in the design, deployment and updating of AI technologies used in health. AI developers include professionals with expertise in computer science or AI, who often also have a background in clinical or health care. Some AI developers are not sited in health systems, even though the products they design will play an increasingly important role in health. Some providers and hospitals are investing in and designing AI technologies and should consider the issues listed below with their existing ethical obligations as medical providers.&lt;/p&gt;

&lt;p id=&quot;_3e22fc21-9220-e176-5547-92907bcb7ac7&quot;&gt;Developers, research organizations and companies should consider systems to ensure that the values, principles and processes that guide their operations are aligned with the expectations of health systems.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>006920</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-a2'>sec-a2</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-a2&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Considerations for ministries of health&lt;/title&gt;
&lt;p id=&quot;_f472bbe1-f604-f98b-26d9-525758b01829&quot;&gt;The following considerations are intended for ministries of health, which will have the primary responsibility for determining whether and how AI technologies should be integrated into health systems, the conditions under which they should be used, the protection of individuals that must accompany use of such technologies and policies that can address both expected and unexpected ethical challenges. Evaluation, regulation, deployment and oversight of AI technologies will require inter-ministerial coordination. Thus, while these considerations are directed to ministries of health, implementation will require collaboration with other relevant ministries, such as of information technology and education.&lt;/p&gt;

&lt;p id=&quot;_45993a57-c087-6e7a-d2e2-5932b3c7dd46&quot;&gt;These considerations are not comprehensive but may be a starting-point for ministries of health to ensure that the use of AI technologies is consonant with the wider objective of the government to provide affordable, equitable, appropriate, effective health care, with the goal of attaining universal health coverage. Three areas should be considered: how ministries should protect the health and safety of patients, how they should prepare for the introduction and use of AI technologies and how they should address ethical and legal challenges and protect human rights.&lt;/p&gt;</pre></td><td>2</td></tr>
<tr class="severity2">
<td>007230</td><th><code><a href='/__w/mn-samples-itu/mn-samples-itu/_site/documents/T-FG-AI4H-2022-MSW/en.html#sec-a3'>sec-a3</a></code></th>
<td>Hanging paragraph in clause</td><td><pre>&lt;clause id=&quot;sec-a3&quot; inline-header=&quot;false&quot; obligation=&quot;normative&quot;&gt;
&lt;title&gt;Considerations for health-care institutions and providers&lt;/title&gt;
&lt;p id=&quot;_658205b0-04ff-2200-084c-93a2d1cefd79&quot;&gt;The following considerations are intended for health-care institutions and providers, such as hospitals, doctors and nurses. While programmers may be those primarily responsible for the design of AI technologies and ministries of health and regulatory agencies for approval and selection of such technologies for use, health-care providers determine which technologies to use and how and may also provide direct feedback to the health-care system, the medical community and the designers of the technologies about whether they meet the needs of patients.&lt;/p&gt;

&lt;p id=&quot;_62153b5e-8db8-5d2e-c590-195cbed9ed2b&quot;&gt;The following is not comprehensive but may be used as a starting point as health-care providers increase use of AI for health care. Use of AI technologies for health outside regular health-care settings is discussed in  &lt;xref target=&quot;sec-3-1&quot;/&gt; of this document. Three areas are considered: whether the AI technology is necessary and appropriate; whether the context in which the AI technology will be used is appropriate; and whether a health-care provider should use a particular AI technology.&lt;/p&gt;</pre></td><td>2</td></tr>
</tbody></table>
<h2 id="Metanorma_XML_Syntax">Metanorma XML Syntax</h2>
<table border="1">
<thead><th width="5%">Line</th><th width="20%">ID</th>
<th width="30%">Message</th><th width="40%">Context</th><th width="5%">Severity</th></thead>
<tbody>
<tr class="severity2">
<td></td><th><code>XML Line 000010:30</code></th>
<td>definition of "OlAttr" in "include" does not override anything</td><td><pre></pre></td><td>2</td></tr>
</tbody></table>
</body></html>
